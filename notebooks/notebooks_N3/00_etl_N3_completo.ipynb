{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5c84d5",
   "metadata": {},
   "source": [
    "# N3 â€” 00_ETL (GeraÃ§Ã£o do dataset limpo)\n",
    "\n",
    "Este notebook:\n",
    "- **Baixa (se necessÃ¡rio) o dataset original diretamente do GitHub** (URL raw)\n",
    "- Cria as pastas em `data/` automaticamente\n",
    "- Realiza limpeza bÃ¡sica e engenharia de atributos\n",
    "- Gera o dataset final para modelagem em `data/dataset_processado_N3/`\n",
    "\n",
    "**Entrada (cache local):** `data/dataset_original/tb_mercadoimob.csv`  \n",
    "**Fonte (GitHub raw):** `data/dataset_original/tb_mercadoimob.csv` no repositÃ³rio `N3_Ciencia_Dados`  \n",
    "**SaÃ­da:** `data/dataset_processado_N3/base_modelagem.csv`  \n",
    "**RelatÃ³rio ETL:** `data/dataset_processado_N3/etl_report.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aca02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "def find_project_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"Sobe diretÃ³rios atÃ© encontrar um marcador do projeto (requirements.txt ou pasta data).\"\"\"\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"requirements.txt\").exists() or (p / \"data\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "ROOT = find_project_root()\n",
    "\n",
    "# URL RAW correta (sem /refs/heads/)\n",
    "RAW_URL = \"https://raw.githubusercontent.com/zilioalberto/N3_Ciencia_Dados/main/data/dataset_original/tb_mercadoimob.csv\"\n",
    "\n",
    "# Caminho local (cache)\n",
    "RAW_PATH = ROOT / \"data\" / \"dataset_original\" / \"tb_mercadoimob.csv\"\n",
    "RAW_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SaÃ­das\n",
    "OUT_DIR = ROOT / \"data\" / \"dataset_processado_N3\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"base_modelagem.csv\"\n",
    "REPORT_PATH = OUT_DIR / \"etl_report.json\"\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"RAW_PATH:\", RAW_PATH)\n",
    "print(\"OUT_PATH:\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Carregar dados (GitHub -> cache local)\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def _detect_sep_from_header(text: str) -> str:\n",
    "    header = (text.splitlines()[0] if text else \"\")\n",
    "    return \";\" if header.count(\";\") > header.count(\",\") else \",\"\n",
    "\n",
    "def _read_csv_text(text: str) -> pd.DataFrame:\n",
    "    sep = _detect_sep_from_header(text)\n",
    "    return pd.read_csv(StringIO(text), sep=sep)\n",
    "\n",
    "def load_csv_with_cache(url: str, local_path: Path) -> pd.DataFrame:\n",
    "    if local_path.exists():\n",
    "        print(\"âœ… Lendo do cache local:\", local_path)\n",
    "        return pd.read_csv(local_path)\n",
    "\n",
    "    print(\"â¬‡ï¸ Baixando do GitHub:\", url)\n",
    "    r = requests.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    df = _read_csv_text(r.text)\n",
    "\n",
    "    print(\"ðŸ’¾ Salvando no cache local:\", local_path)\n",
    "    df.to_csv(local_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_raw = load_csv_with_cache(RAW_URL, RAW_PATH)\n",
    "\n",
    "print(\"Shape raw:\", df_raw.shape)\n",
    "display(df_raw.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) FunÃ§Ãµes utilitÃ¡rias\n",
    "\n",
    "def to_numeric_safe(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converte para numÃ©rico aceitando formatos BR (1.234,56) e sÃ­mbolos.\"\"\"\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return s\n",
    "\n",
    "    x = s.astype(str).str.strip()\n",
    "\n",
    "    # remove espaÃ§os e textos como \"R$\"\n",
    "    x = x.str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    x = x.str.replace(\"R$\", \"\", regex=False)\n",
    "\n",
    "    # mantÃ©m apenas dÃ­gitos e separadores\n",
    "    x = x.str.replace(r\"[^0-9,\\.\\-]\", \"\", regex=True)\n",
    "\n",
    "    # casos:\n",
    "    # - se tiver '.' e ',' -> assume '.' milhar e ',' decimal\n",
    "    has_dot = x.str.contains(r\"\\.\", regex=True)\n",
    "    has_comma = x.str.contains(\",\", regex=False)\n",
    "\n",
    "    x = x.where(~(has_dot & has_comma), x.str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False))\n",
    "    # - se tiver sÃ³ ',' -> assume ',' decimal\n",
    "    x = x.where(~(~has_dot & has_comma), x.str.replace(\",\", \".\", regex=False))\n",
    "\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def normalize_text(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.fillna(\"\")\n",
    "         .astype(str)\n",
    "         .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "         .str.strip()\n",
    "         .str.lower()\n",
    "    )\n",
    "\n",
    "def to_binary_flag(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normaliza colunas Sim/NÃ£o, True/False, 1/0 para 0/1.\"\"\"\n",
    "    if pd.api.types.is_bool_dtype(s):\n",
    "        return s.astype(\"int8\")\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return (s.fillna(0) != 0).astype(\"int8\")\n",
    "\n",
    "    x = normalize_text(s)\n",
    "    true_set = {\"1\", \"true\", \"t\", \"sim\", \"s\", \"yes\", \"y\"}\n",
    "    return x.isin(true_set).astype(\"int8\")\n",
    "\n",
    "# PadrÃµes (texto -> flags)\n",
    "vista_patterns = [\n",
    "    r\"\\bvista\\s*(para\\s*o\\s*)?mar\\b\",\n",
    "    r\"\\bfrente\\s*(para\\s*o\\s*)?mar\\b\",\n",
    "    r\"\\bfrente\\s*ao\\s*mar\\b\",\n",
    "    r\"\\bvista\\s*mar\\b\",\n",
    "]\n",
    "mobiliado_patterns = [\n",
    "    r\"\\bmobiliad[oa]\\b\",\n",
    "    r\"\\bsemi\\s*mobiliad[oa]\\b\",\n",
    "    r\"\\bcom\\s*m[Ã³o]veis\\b\",\n",
    "    r\"\\bcompleto\\b\",\n",
    "]\n",
    "\n",
    "vista_re = re.compile(\"|\".join(vista_patterns), flags=re.IGNORECASE)\n",
    "mobiliado_re = re.compile(\"|\".join(mobiliado_patterns), flags=re.IGNORECASE)\n",
    "\n",
    "def build_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cria colunas binÃ¡rias com base em texto disponÃ­vel.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # tenta usar colunas de texto comuns (se existirem)\n",
    "    text_cols_candidates = [\n",
    "        \"titulo\", \"descricao\", \"caracteristicas\", \"observacoes\", \"anuncio\", \"texto\"\n",
    "    ]\n",
    "    text_cols = [c for c in text_cols_candidates if c in df.columns]\n",
    "\n",
    "    if not text_cols:\n",
    "        # fallback: tenta qualquer coluna object de tamanho razoÃ¡vel\n",
    "        obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "        text_cols = obj_cols[:4]  # limita\n",
    "\n",
    "    blob = \"\"\n",
    "    for c in text_cols:\n",
    "        blob = blob + \" \" + normalize_text(df[c])\n",
    "\n",
    "    df[\"vista_mar_bin\"] = blob.str.contains(vista_re, na=False).astype(\"int8\")\n",
    "    df[\"mobiliado_bin\"] = blob.str.contains(mobiliado_re, na=False).astype(\"int8\")\n",
    "    return df\n",
    "\n",
    "def clip_outliers_iqr(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Clipa valores por IQR (nÃ£o remove linhas).\"\"\"\n",
    "    s = s.copy()\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if pd.isna(iqr) or iqr == 0:\n",
    "        return s\n",
    "    low = q1 - k * iqr\n",
    "    high = q3 + k * iqr\n",
    "    return s.clip(lower=low, upper=high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) SeleÃ§Ã£o e limpeza bÃ¡sica\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Colunas numÃ©ricas principais (se existirem)\n",
    "num_cols = [\n",
    "    \"area\", \"valor\", \"iptu\", \"taxa_condominial\",\n",
    "    \"num_quartos\", \"num_banheiros\", \"num_suites\", \"num_vagas_garagem\", \"num_andares\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_numeric_safe(df[c])\n",
    "\n",
    "# Colunas binÃ¡rias (se existirem)\n",
    "bin_cols = [\"imovel_lancamento\", \"bl_temporada\"]\n",
    "for c in bin_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = to_binary_flag(df[c])\n",
    "\n",
    "# Flags a partir de texto\n",
    "df = build_flags(df)\n",
    "\n",
    "# Filtrar tipo de negÃ³cio (se existir)\n",
    "if \"tipo_negocio\" in df.columns:\n",
    "    tipo = normalize_text(df[\"tipo_negocio\"])\n",
    "    df = df[tipo.str.contains(\"venda\", na=False)].copy()\n",
    "\n",
    "# Garantir area positiva (se existir)\n",
    "if \"area\" in df.columns:\n",
    "    df = df[df[\"area\"].notna() & (df[\"area\"] > 0)].copy()\n",
    "\n",
    "# Definir a variÃ¡vel alvo (preco_m2)\n",
    "if \"preco_m2\" in df.columns:\n",
    "    df[\"preco_m2\"] = to_numeric_safe(df[\"preco_m2\"])\n",
    "elif \"valor\" in df.columns and \"area\" in df.columns:\n",
    "    df[\"preco_m2\"] = df[\"valor\"] / df[\"area\"]\n",
    "elif \"valor_m2\" in df.columns:\n",
    "    df[\"preco_m2\"] = to_numeric_safe(df[\"valor_m2\"])\n",
    "else:\n",
    "    raise KeyError(\"NÃ£o encontrei colunas para calcular 'preco_m2' (ex.: valor+area, preco_m2 ou valor_m2).\")\n",
    "\n",
    "# Remover/prevenir valores invÃ¡lidos\n",
    "df = df[df[\"preco_m2\"].notna() & (df[\"preco_m2\"] > 0)].copy()\n",
    "\n",
    "# Clipping de outliers\n",
    "df[\"preco_m2\"] = clip_outliers_iqr(df[\"preco_m2\"], k=1.5)\n",
    "\n",
    "print(\"Shape apÃ³s filtros:\", df.shape)\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Dataset final para modelagem\n",
    "\n",
    "target_col = \"preco_m2\"\n",
    "\n",
    "candidate_features = [\n",
    "    # numÃ©ricas\n",
    "    \"area\", \"iptu\", \"taxa_condominial\",\n",
    "    \"num_quartos\", \"num_banheiros\", \"num_suites\", \"num_vagas_garagem\", \"num_andares\",\n",
    "    # categÃ³ricas\n",
    "    \"tipo_imovel\", \"estado_construcao\", \"fonte\",\n",
    "    # binÃ¡rias\n",
    "    \"imovel_lancamento\", \"bl_temporada\",\n",
    "    # texto->flags\n",
    "    \"vista_mar_bin\", \"mobiliado_bin\",\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in candidate_features if c in df.columns]\n",
    "\n",
    "df_model = df[feature_cols + [target_col]].copy()\n",
    "\n",
    "# Ajustes finais de tipos\n",
    "for c in feature_cols:\n",
    "    if c in [\"tipo_imovel\", \"estado_construcao\", \"fonte\"]:\n",
    "        df_model[c] = df_model[c].fillna(\"desconhecido\").astype(str)\n",
    "    elif c in [\"vista_mar_bin\", \"mobiliado_bin\", \"imovel_lancamento\", \"bl_temporada\"]:\n",
    "        df_model[c] = to_binary_flag(df_model[c])\n",
    "    else:\n",
    "        df_model[c] = to_numeric_safe(df_model[c])\n",
    "\n",
    "df_model[target_col] = to_numeric_safe(df_model[target_col])\n",
    "\n",
    "# Salvar\n",
    "df_model.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "report = {\n",
    "    \"raw_url\": RAW_URL,\n",
    "    \"raw_path\": str(RAW_PATH),\n",
    "    \"out_path\": str(OUT_PATH),\n",
    "    \"raw_shape\": list(df_raw.shape),\n",
    "    \"after_basic_filters_shape\": list(df.shape),\n",
    "    \"model_shape\": list(df_model.shape),\n",
    "    \"features\": feature_cols,\n",
    "    \"target\": target_col,\n",
    "    \"notes\": [\n",
    "        \"O dataset foi filtrado para tipo_negocio==Venda (se a coluna existir).\",\n",
    "        \"preco_m2 possui clipping por IQR para reduzir influÃªncia de outliers sem descartar linhas.\",\n",
    "        \"O CSV Ã© baixado do GitHub e cacheado em RAW_PATH quando nÃ£o existir localmente.\",\n",
    "    ],\n",
    "}\n",
    "REPORT_PATH.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Salvo:\", OUT_PATH)\n",
    "print(\"âœ… Salvo:\", REPORT_PATH)\n",
    "display(df_model.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
